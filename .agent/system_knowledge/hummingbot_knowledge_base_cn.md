# Hummingbot 知识库与性能优化经验汇总

本文档记录了 2026-01-01 关于“回测数据加载优化”任务的核心架构洞察、踩坑记录及解决方案，旨在为后续开发提供参考，避免重复犯错。

## 性能优化：参考 [Mac Studio 性能优化实战指引](file:///Users/microtoy/.gemini/antigravity/brain/e319a0da-e4b9-4354-9932-bfdc347339c1/optimization_lessons_cn.md) 以获取多核加速和 IO 优化的详细经验。

## 1. Hummingbot 回测引擎底层机制

### 数据初始化瓶颈 (The Bottleneck)
*   **现象**：在原生 Hummingbot V2 中，`initialize_backtesting_data_provider` 经常会为每次回测重新从交易所抓取数据。
    *   **发现**：对于 30 天的 1m 频率数据，网络抓取需 10-25 秒，而本地磁盘读取仅需 **<0.1 秒**。
    *   **教训**：对于专业级回测试，本地数据持久化缓存是必须项。

### 历史数据缓冲陷阱 (History Buffer Trap)
*   **洞察**：策略控制器（如 `MACrossStrategy`）通常需要 `max_records=500` 甚至更多的历史数据来初始化技术指标。
*   **坑点**：如果用户同步的是 `12月01日 - 12月31日` 的数据，但策略计算需要前推 500 条（即 11 月底的数据），简单的范围检查会判定为“缺失”，导致缓存失效重下。
*   **方案**：在数据同步阶段，必须自动增加 **2000 条 K 线左右的 Buffer**，确保策略在磁盘中能找到完整的计算依据。

## 2. 核心优化方案：贪婪增量下载 (Greedy Delta)

### 问题：极小误差导致全量重下
*   **坑点**：由于 59 秒的偏移（如请求到 23:59:59 而本地只有 23:59:00）或微小的 Buffer 缺失，系统以往会直接抛弃本地几十兆的文件，重新从网络下载。
*   **架构转变**：从“全中/全放”切换为 **“贪婪补全 (Greedy Delta Filling)”**。
    *   **逻辑**：精确识别本地缺失的特定时间段（前缀 Prefix、后缀 Suffix 或中间缺环）。
    *   **动作**：仅下载这部分增量，使用 `pd.concat` + `drop_duplicates` 瞬间合并入本地 CSV，实现“越用越快”。

### 问题：“今天”数据的请求循环
*   **坑点**：当回测选到“今天”时，系统默认请求到今晚 23:59:59。请求未来数据会导致 API 超时，且缓存永远无法“完整”。
*   **方案**：**时间戳封顶 (Timestamp Capping)**。永远将请求的结束时间限制在 `min(请求结束, 当前时间 - 60s)`。
*   **容差处理**：针对最近的数据，实施 **24 小时容差控制**。如果本地数据已到昨天或今天早些时候，且用户只是进行粗略迭代，则不强制刷新，优先保证瞬时启动。

## 3. 环境与部署建议

### 挂载一致性
*   **要点**：在多容器（Dashboard + API）架构中，`data/candles` 目录必须挂载到**完全一致的项目相对路径**，防止路径解析导致的“文件不存在”假象。

### .gitignore 配置
*   **规范**：数据文件大且多，应在根目录使用锚点（如 `/data/`）将其排除在 Git 追踪外，但保留目录结构，确保持久化卷的稳定性。

## 4. 调试与验证方法论

### 容器内诊断
*   **工具**：活用 `cache_diagnostic.py` 等轻量级 Python 脚本在容器内直接读取 CSV。不要仅依赖 UI 反馈，要通过打印 `min_ts` 和 `max_ts` 来确诊缓存未命中的真实原因。
*   **透明化日志**：在 Patch 代码中加入 `✅ [CACHE HIT]` 或 `📥 [DELTA START]` 等可视化日志，是建立用户信任和快速定位问题的关键。

---
*更新日期：2026-01-01*
