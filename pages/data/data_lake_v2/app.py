import streamlit as st
import pandas as pd
from datetime import datetime, date, timedelta
import sys
import os

# ç¡®ä¿å¯ä»¥å¯¼å…¥ data_lake
sys.path.append(os.getcwd())

from data.data_lake.manager import get_lake_manager

st.set_page_config(layout="wide", page_title="Data Lake V2")

LAKE = get_lake_manager()

st.title("ğŸ›¡ï¸ è¡Œæƒ…æ•°æ®ç®¡ç† V2 (Data Lake)")
st.info("åŸºäºåˆ†ç‰‡å­˜å‚¨çš„æ•°æ®ä¸­å¿ƒï¼šé›¶é”å†²çªï¼Œæé€Ÿæ£€æµ‹ï¼Œ100% å®‰å…¨ã€‚")

# --- å®æ—¶è¿›åº¦ä¸­å¿ƒ (å…¬å…±å±‚) ---
st.subheader("ğŸ“Š å®æ—¶ä»»åŠ¡ä¸­å¿ƒ")

@st.fragment(run_every="2s")
def render_progress_center():
    # è·å–æœ€æ–°çŠ¶æ€
    current_status = LAKE.get_status()
    dl_status = current_status.get("download", {})
    slots = current_status.get("slots", [])
    active_workers = len([s for s in slots if s is not None])
    max_workers = len(slots)
    
    if dl_status.get("total", 0) > 0:
        # æ€»è¿›åº¦æ  (æ¨¡ä»¿ V1 é£æ ¼)
        percent = dl_status.get("percent", 0)
        completed = dl_status.get("completed", 0)
        total = dl_status.get("total", 0)
        failed = dl_status.get("failed", 0)
        
        # çŠ¶æ€ä¸æ§åˆ¶é¡¹
        is_paused = LAKE.is_paused()
        status_emoji = "â¸ï¸ æš‚åœä¸­" if is_paused else "ğŸš€ è¿è¡Œä¸­"
        
        # ä½¿ç”¨å¸¦æœ‰çŠ¶æ€æè¿°çš„è¿›åº¦æ¡
        status_text = f"æ€»è¿›åº¦: {completed}/{total} ( {percent:.1f}% )"
        if failed > 0:
            status_text += f" | âš ï¸ {failed} å¤±è´¥/å–æ¶ˆ"
        
        # å¢åŠ å¹¶å‘ä¿¡æ¯ä¸æ§åˆ¶æŒ‰é’®
        col_prog, col_pause, col_stop = st.columns([3, 1, 1])
        with col_prog:
            st.progress(percent / 100, text=status_text)
            st.caption(f"{status_emoji} | å¹¶å‘: {active_workers}/{max_workers} | âš¡ åŸºäº asyncio é«˜å¹¶å‘å¼•æ“")
        
        with col_pause:
            if is_paused:
                if st.button("â–¶ï¸ æ¢å¤ä¸‹è½½", use_container_width=True, type="primary"):
                    LAKE.resume_download()
                    st.rerun()
            else:
                if st.button("â¸ï¸ æš‚åœä¸‹è½½", use_container_width=True):
                    LAKE.pause_download()
                    st.rerun()
        
        with col_stop:
            if st.button("â¹ï¸ ç»ˆæ­¢å…¨éƒ¨", use_container_width=True, type="secondary", help="æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡åˆ—è¡¨"):
                LAKE.stop_download()
                st.rerun()
        
        # åˆ†é¡¹ä¸‹è½½å¡ç‰‡
        details = dl_status.get("details", {})
        if details:
            # åªå±•ç¤ºæ­£åœ¨ä¸‹è½½æˆ–æœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œä¿æŒç•Œé¢ç®€æ´
            active_keys = [k for k, v in details.items() if v["downloading"] > 0 or v["percent"] < 100]
            if active_keys:
                # ä½¿ç”¨ 3 åˆ—å¸ƒå±€ä»¥é€‚é… 15 çº¿ç¨‹å±•ç¤º
                cols = st.columns(3)
                for i, key in enumerate(active_keys[:15]): # å±•ç¤ºå‰ 15 ä¸ªæ´»è·ƒä»»åŠ¡
                    info = details[key]
                    with cols[i % 3]:
                        # ç®€åŒ–ç‰ˆåˆ†é¡¹è¿›åº¦
                        status_label = f"**{key}** ({info['completed']}/{info['total']} å¤©)"
                        if info.get("failed", 0) > 0:
                            status_label += f" | âš ï¸ {info['failed']} å¤±è´¥"
                        st.caption(status_label)
                        st.progress(info["percent"] / 100)
                        
                        # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œå±•ç¤ºç¬¬ä¸€æ¡é”™è¯¯
                        if info.get("error"):
                            st.caption(f":red[{info['error']}]")
                if len(active_keys) > 15:
                    st.write(f"...ç­‰å…¶ä½™ {len(active_keys)-15} ä¸ªä»»åŠ¡æ­£åœ¨æ’é˜Ÿ")
            else:
                st.success("âœ… å½“å‰æ‰¹æ¬¡æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
    else:
        st.info("å½“å‰æ— æ´»åŠ¨ä»»åŠ¡ã€‚åœ¨ä¸‹æ–¹é…ç½®å‚æ•°å¹¶å¯åŠ¨ä¸‹è½½ã€‚")

render_progress_center()
st.markdown("---")

# --- SIDEBAR ---
st.sidebar.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
status = LAKE.get_status()

st.sidebar.metric("å­˜å‚¨æ–‡ä»¶æ•°", status["storage"]["total_files"])
st.sidebar.metric("å­˜å‚¨æ€»å¤§å°", f"{status['storage']['total_size_mb']} MB")

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“¥ ä¸‹è½½è¿›åº¦")
prog = status["download"]
if prog["total"] > 0:
    st.sidebar.progress(prog["percent"] / 100)
    st.sidebar.write(f"ä»»åŠ¡: {prog['completed']} / {prog['total']}")
    st.sidebar.write(f"è¿›è¡Œä¸­: {prog['downloading']} | å¤±è´¥: {prog['failed']}")
else:
    st.sidebar.write("æš‚æ— æ´»è·ƒä¸‹è½½ä»»åŠ¡")

if st.sidebar.button("ğŸ”„ å¼ºåˆ¶åˆ·æ–°é¡µé¢"):
    st.rerun()

# --- MAIN PAGE TABS ---
tab1, tab2, tab3 = st.tabs(["ğŸš€ çµæ´»ä¸‹è½½ & ä¿®å¤", "ğŸ“‹ æ•°æ®èµ„äº§æ¦‚è§ˆ", "ğŸ›¡ï¸ å…¼å®¹æ€§æ¡¥æ¥ (Export)"])

# TAB 1: çµæ´»ä¸‹è½½
with tab1:
    st.subheader("ğŸ› ï¸ å‚æ•°é…ç½®")
    
    # è·å–é»˜è®¤å¸ç§åˆ—è¡¨ (ç›´æ¥è¯»å– yaml ä»¥å… import é”™è¯¯)
    import yaml
    symbols_path = "config/symbols.yaml"
    config_symbols_list = []
    try:
        if os.path.exists(symbols_path):
            with open(symbols_path, 'r') as f:
                config_symbols = yaml.safe_load(f)
                config_symbols_list = [s['trading_pair'] for s in config_symbols.get('symbols', [])]
    except Exception as e:
        st.warning(f"åŠ è½½ symbols.yaml å¤±è´¥: {e}")

    @st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜ä¸€æ¬¡ï¼Œæé«˜æ€§èƒ½
    def get_market_rankings(limit, rank_type="market_cap"):
        import asyncio
        try:
            return asyncio.run(LAKE.get_top_pairs(limit, rank_type=rank_type))
        except:
            if rank_type == "market_cap":
                return ["BTC-USDT", "ETH-USDT", "SOL-USDT", "BNB-USDT", "XRP-USDT", "ADA-USDT", "DOGE-USDT", "TRX-USDT", "LINK-USDT", "DOT-USDT"][:limit]
            else:
                return ["BTC-USDT", "ETH-USDT", "SOL-USDT", "PEPE-USDT", "DOGE-USDT", "SHIB-USDT"][:limit]

    col_rank1, col_rank2 = st.columns(2)
    with col_rank1:
        rank_mode = st.selectbox("ğŸ“Š æ’åé€‰æ‹©æ¨¡å¼", ["ğŸŒ å…¨çƒå¸‚å€¼ (ç¨³å¥ä¼˜å…ˆ)", "ğŸ”¥ 24h çƒ­åº¦ (æ´»è·ƒæ¬¡é€‰)", "æ‰‹åŠ¨é€‰æ‹© (æœ¬åœ°é…ç½®)"], index=0)
    
    with col_rank2:
        if "æ‰‹åŠ¨" not in rank_mode:
            rank_size = st.selectbox("ğŸ¯ TOP N è§„æ¨¡", ["TOP 10", "TOP 20", "TOP 50", "TOP 100", "TOP 200"], index=0)
            target_limit = int(rank_size.split(" ")[1])
        else:
            st.write(" ") # å ä½
            target_limit = 0

    if "å¸‚å€¼" in rank_mode:
        top_pairs = get_market_rankings(target_limit, rank_type="market_cap")
        all_options = sorted(list(set(config_symbols_list + top_pairs)))
        selected_pairs = st.multiselect("é€‰æ‹©äº¤æ˜“å¯¹", all_options, default=top_pairs)
    elif "çƒ­åº¦" in rank_mode:
        top_pairs = get_market_rankings(target_limit, rank_type="volume")
        all_options = sorted(list(set(config_symbols_list + top_pairs)))
        selected_pairs = st.multiselect("é€‰æ‹©äº¤æ˜“å¯¹", all_options, default=top_pairs)
    else:
        all_options = sorted(list(set(config_symbols_list + ["BTC-USDT", "ETH-USDT"])))
        selected_pairs = st.multiselect("é€‰æ‹©äº¤æ˜“å¯¹", all_options, default=config_symbols_list)

    st.subheader("2ï¸âƒ£ é€‰æ‹©å‘¨æœŸ")
    intervals = ["1m", "5m", "15m", "30m", "1h", "4h", "1d"]
    selected_intervals = st.multiselect("æ—¶é—´ç²’åº¦", intervals, default=["1m", "1h"])
    
    st.subheader("3ï¸âƒ£ é€‰æ‹©æ—¥æœŸèŒƒå›´")
    col_date1, col_date2 = st.columns(2)
    with col_date1:
        start_date = st.date_input("èµ·å§‹æ—¥æœŸ", date.today() - timedelta(days=7))
    with col_date2:
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", date.today())
        
    st.subheader("4ï¸âƒ£ ä¸‹è½½è®¾ç½®")
    col_set1, col_set2 = st.columns([1, 2])
    with col_set1:
        use_proxy = st.checkbox("ä½¿ç”¨ä»£ç†ä¸‹è½½", value=False)
    with col_set2:
        proxy_url = st.text_input("ä»£ç†åœ°å€", value="http://host.docker.internal:7890", disabled=not use_proxy)

    st.markdown("---")
    
    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("ğŸš€ å¼€å§‹ä¸‹è½½/è¡¥é½æµ‹è¯• (ä»…å‰3å¤©)", type="secondary", use_container_width=True):
            test_end = start_date + timedelta(days=min(2, (end_date - start_date).days))
            LAKE.start_download(selected_pairs, selected_intervals, start_date, test_end, use_proxy=use_proxy, proxy_url=proxy_url)
            st.success(f"å·²è§¦å‘æµ‹è¯•ä¸‹è½½: {selected_pairs}")
            
    with col_btn2:
        if st.button("ğŸ”¥ æ‰§è¡Œå…¨é‡ä¸‹è½½ä»»åŠ¡", type="primary", use_container_width=True):
            LAKE.start_download(selected_pairs, selected_intervals, start_date, end_date, use_proxy=use_proxy, proxy_url=proxy_url)
            st.success(f"å·²æŒ‰æŒ‡å®šèµ·å§‹èŒƒå›´è§¦å‘ä¸‹è½½")

    st.markdown("---")
    st.subheader("ğŸ’¡ æ™ºèƒ½ç»´æŠ¤")
    col_smart1, col_smart2 = st.columns(2)
    with col_smart1:
        years = st.number_input("è¡¥é½å†å²å¹´é™", min_value=1, max_value=10, value=3)
        if st.button("ğŸ©¹ ä¸€é”®è¡¥é½æ‰€æœ‰ç¼ºå¤±å†å²", use_container_width=True):
            LAKE.auto_fill_history(selected_pairs, selected_intervals, years=years, use_proxy=use_proxy, proxy_url=proxy_url)
            st.info("å·²å¯åŠ¨åå°å†å²æ‰«æä¸è¡¥é½åŠŸèƒ½...")

    with col_smart2:
        st.write(" ") # å ä½
        st.write(" ") # å ä½
        if st.button("ğŸ”„ åŒæ­¥æ›´æ–°è‡³æœ€æ–°æ—¶åˆ»", use_container_width=True):
            # å°†ç»“æŸæ—¥æœŸè®¾ä¸ºä»Šå¤©
            LAKE.start_download(selected_pairs, selected_intervals, date.today() - timedelta(days=2), date.today(), use_proxy=use_proxy, proxy_url=proxy_url)
            st.info("å·²å¯åŠ¨å¢é‡åŒæ­¥ä»»åŠ¡...")


# TAB 2: æ•°æ®èµ„äº§
with tab2:
    c1, c2 = st.columns([5, 1])
    with c1:
        st.subheader("æ•°æ®æ¹–å­˜å‚¨è¯¦æƒ…")
    with c2:
        if st.button("ğŸ” æ·±åº¦è´¨æ£€", help="ç‰©ç†æ‰«ææ¯ä¸ªæ–‡ä»¶ï¼Œæ ¸å¯¹è¡Œæ•° (1m=1440, 1h=24)"):
            LAKE.get_status(audit=True)
            st.rerun()

    def render_coverage_ribbon(bits):
        if not bits: return ""
        # ä½¿ç”¨ CSS Gradient ç”Ÿæˆåƒæ¡å½¢ç ä¸€æ ·çš„çŠ¶æ€çº¿
        colors = []
        step = 100 / len(bits)
        for i, b in enumerate(bits):
            color = "#2E7D32" if b == 1 else "#E0E0E0" # ç»¿è‰² vs ç°è‰²
            colors.append(f"{color} {i*step}%")
            colors.append(f"{color} {(i+1)*step}%")
        
        gradient = ", ".join(colors)
        html = f"""
        <div style="
            width: 100%; 
            height: 12px; 
            background: linear-gradient(90deg, {gradient}); 
            border-radius: 6px;
            margin: 5px 0;
            box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);
        "></div>
        """
        return html

    pairs_data = status["storage"]["pairs"]
    if pairs_data:
        for k, v in pairs_data.items():
            with st.container():
                col1, col2, col3 = st.columns([2, 2, 1])
                with col1:
                    st.markdown(f"**{k}**")
                with col2:
                    start_str = v.get('start').isoformat() if v.get('start') else "-"
                    end_str = v.get('end').isoformat() if v.get('end') else "-"
                    st.write(f"ğŸ“… {start_str} è‡³ {end_str}")
                with col3:
                    rows = v.get('total_rows', 0)
                    st.write(f"ğŸ“ˆ {rows:,} æ¡è®°å½•")
                
                # ç¬¬äºŒè¡Œè¯¦æƒ…
                m_col1, m_col2, m_col3, m_col4 = st.columns([3, 1, 1, 1])
                with m_col1:
                    # æ¸²æŸ“çŠ¶æ€çº¿
                    parts = k.split(":")
                    if len(parts) == 3:
                        bits = LAKE.storage.get_coverage(parts[0], parts[1], parts[2])
                        st.markdown(render_coverage_ribbon(bits), unsafe_allow_html=True)
                
                with m_col2:
                    missing_count = v.get('missing_days', 0)
                    if missing_count > 0:
                        # ä½¿ç”¨ expander å±•ç¤ºå…·ä½“æ—¥æœŸ
                        with st.expander(f"ğŸ©¹ {missing_count} å¤©ç¼ºå£"):
                            parts = k.split(":")
                            missing_list = LAKE.storage.get_missing_days(parts[0], parts[1], parts[2])
                            st.write([d.isoformat() for d in missing_list[:50]])
                    else:
                        st.write("âœ… èŒƒå›´å®Œæ•´")
                
                with m_col3:
                    incomplete_count = v.get('incomplete_days', 0)
                    if incomplete_count > 0:
                        with st.expander(f"âš ï¸ {incomplete_count} å¤©å¼‚å¸¸", help="è¡Œæ•°ä¸è¶³çš„å¤©æ•°"):
                            st.write(v.get('incomplete_list', [])[:50])
                    else:
                        st.write("ğŸ’ å†…å®¹å®Œæ•´")
                
                with m_col4:
                    if st.button("ğŸ› ï¸ æ·±åº¦ä¿®è¡¥", key=f"repair_{k}", help="è¡¥é½ç¼ºå¤±å¹¶é‡åˆ·å¼‚å¸¸å¤©"):
                        parts = k.split(":")
                        # æ¸…ç†å¼‚å¸¸æ–‡ä»¶ä»¥ä¾¿é‡æ–°ä¸‹è½½
                        for d_str in v.get('incomplete_list', []):
                            try:
                                path = LAKE.storage.get_partition_path(parts[0], parts[1], parts[2], d_str)
                                if path.exists(): path.unlink()
                            except: pass
                        
                        LAKE.start_download([parts[1]], [parts[2]], v['start'], v['end'])
                        st.toast(f"å·²å¯åŠ¨ {parts[1]} æ·±åº¦ä¿®è¡¥ä»»åŠ¡")
                st.markdown("---")
    else:
        st.info("æ•°æ®æ¹–ä¸­æš‚æ— åˆ†ç‰‡æ–‡ä»¶")

# --- å…¼å®¹æ€§æ¡¥æ¥ (Export) ---
# æ£€æµ‹ Legacy æ•°æ®å­˜å‚¨è·¯å¾„ï¼ˆå…¼å®¹ Docker æŒ‚è½½ï¼‰
LEGACY_CANDLES_DIR = "data/candles"
if os.path.exists("/tmp/hbot_data/candles"):
    LEGACY_CANDLES_DIR = "/tmp/hbot_data/candles"

with tab3:
    st.subheader("å¯¼å‡ºè‡³ Hummingbot (Legacy CSV)")
    st.write("å°†æ•°æ®æ¹–ä¸­çš„åˆ†ç‰‡åˆå¹¶ä¸º Hummingbot è¯†åˆ«çš„å•ä¸€ CSV æ–‡ä»¶ã€‚")
    
    if selected_pairs:
        target_pair = st.selectbox("é€‰æ‹©è¦å¯¼å‡ºçš„å¸ç§", selected_pairs)
        target_interval = st.selectbox("é€‰æ‹©ç²’åº¦", selected_intervals)
        
        output_filename = f"binance_{target_pair}_{target_interval}.csv"
        # è½¬æ¢æ˜¾ç¤ºè·¯å¾„ï¼Œå¦‚æœæ˜¯ Docker å†…éƒ¨è·¯å¾„ï¼Œæ˜¾ç¤ºä¸ºç”¨æˆ·å‹å¥½çš„ç›¸å¯¹è·¯å¾„
        display_path = f"data/candles/{output_filename}"
        st.code(f"ç›®æ ‡æ–‡ä»¶: {display_path}")
        
        if st.button("ğŸ–‡ï¸ æ‰§è¡Œåˆå¹¶å¹¶è¦†ç›–æ—§ç³»ç»Ÿæ•°æ®"):
            from data.data_lake.merger import DataMerger
            merger = DataMerger(LAKE.storage)
            target_path = os.path.join(LEGACY_CANDLES_DIR, output_filename)
            success = merger.auto_merge_full_history("binance", target_pair, target_interval, target_path)
            if success:
                st.success(f"âœ… å·²æˆåŠŸåˆå¹¶å¹¶è¦†ç›– {output_filename}")
            else:
                st.error("âŒ å¯¼å‡ºå¤±è´¥ï¼šè¯·ç¡®è®¤æ•°æ®æ¹–ä¸­å·²ä¸‹è½½ç›¸å…³æ•°æ®")
    else:
        st.warning("è¯·åœ¨ Tab 1 ä¸­å…ˆé€‰æ‹©ä¸€ä¸ªå¸ç§ã€‚")
