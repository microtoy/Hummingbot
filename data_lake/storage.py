import os
import pandas as pd
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import List, Optional, Union, Dict

class LakeStorage:
    """
    åˆ†ç‰‡å­˜å‚¨ç®¡ç†å™¨ (Partitioned Storage Manager)
    è´Ÿè´£å°†è¡Œæƒ…æ•°æ®æŒ‰å¤©å­˜å‚¨åœ¨ç‹¬ç«‹çš„æ–‡ä»¶ä¸­ï¼Œé˜²æ­¢å¹¶å‘å†²çªã€‚
    ç›®å½•ç»“æ„: base_path/{exchange}/{trading_pair}/{interval}/{year}/{month}/{date}.csv
    """
    def __init__(self, base_path: Union[str, Path, None] = None):
        if base_path:
            self.base_path = Path(base_path)
        else:
            # âš¡ ä¼˜å…ˆä½¿ç”¨æ˜¾å¼ç¯å¢ƒå˜é‡
            env_path = os.getenv("DATA_LAKE_PATH")
            if env_path:
                self.base_path = Path(env_path)
            else:
                # é»˜è®¤æŒ‡å‘å®¹å™¨å†…æŒä¹…åŒ–å·ä½ç½® (dashboard å®¹å™¨æŒ‚è½½äº† ./data -> /home/dashboard/data)
                # ä¹‹å‰æœ‰äº›è„šæœ¬å¯èƒ½å†™å…¥çš„æ˜¯ ./data/lake æˆ– ./data_lake/STORAGEï¼Œè¿™é‡Œç»Ÿé…
                p1 = Path("/home/dashboard/data/lake")
                p2 = Path("/opt/conda/envs/dashboard/lib/python3.12/site-packages/data/lake")
                self.base_path = p1 if p1.exists() else p2 if p2.exists() else p1
        
        self.base_path.mkdir(parents=True, exist_ok=True)
        import logging
        logging.info(f"ğŸ›¡ï¸ LakeStorage persistent path: {self.base_path.absolute()}")

    def get_partition_path(self, exchange: str, trading_pair: str, interval: str, day: Union[date, str]) -> Path:
        """è·å–ç‰¹å®šæ—¥æœŸçš„åˆ†ç‰‡æ–‡ä»¶è·¯å¾„"""
        if isinstance(day, str):
            day = datetime.strptime(day, "%Y-%m-%d").date()
            
        year = str(day.year)
        month = f"{day.month:02d}"
        filename = f"{day.isoformat()}.csv"
        
        path = self.base_path / exchange / trading_pair / interval / year / month / filename
        return path

    def save_day_data(self, df: pd.DataFrame, exchange: str, trading_pair: str, interval: str, day: date):
        """åŸå­æ€§ä¿å­˜ä¸€æ•´å¤©çš„æ•°æ®"""
        path = self.get_partition_path(exchange, trading_pair, interval, day)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å†™å…¥å†é‡å‘½åï¼Œç¡®ä¿åŸå­æ€§
        tmp_path = path.with_suffix(".tmp")
        df.to_csv(tmp_path, index=False)
        tmp_path.replace(path)

    def load_day_data(self, exchange: str, trading_pair: str, interval: str, day: date) -> Optional[pd.DataFrame]:
        """åŠ è½½ç‰¹å®šæ—¥æœŸçš„æ•°æ®"""
        path = self.get_partition_path(exchange, trading_pair, interval, day)
        if not path.exists():
            return None
        return pd.read_csv(path)

    def list_existing_days(self, exchange: str, trading_pair: str, interval: str) -> List[date]:
        """åˆ—å‡ºå·²å­˜åœ¨çš„æ‰€æœ‰å¤© (ä¼˜åŒ–ç‰ˆï¼šé¿å… glob)"""
        dir_path = self.base_path / exchange / trading_pair / interval
        if not dir_path.exists():
            return []
            
        existing_days = []
        # æŒ‰ç…§ YYYY/MM ç»“æ„éå†
        for year_dir in dir_path.iterdir():
            if not year_dir.is_dir(): continue
            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir(): continue
                for file in month_dir.iterdir():
                    if file.suffix == ".csv":
                        try:
                            day_str = file.stem
                            day = datetime.strptime(day_str, "%Y-%m-%d").date()
                            existing_days.append(day)
                        except: continue
        return sorted(existing_days)

    def get_missing_days(self, exchange: str, trading_pair: str, interval: str) -> List[date]:
        """è·å–å·²æœ‰èŒƒå›´å†…çš„æ‰€æœ‰ç¼ºå¤±æ—¥æœŸ"""
        days = self.list_existing_days(exchange, trading_pair, interval)
        if not days:
            return []
        
        start, end = days[0], days[-1]
        all_days = set()
        curr = start
        while curr <= end:
            all_days.add(curr)
            curr += timedelta(days=1)
            
        existing = set(days)
        missing = sorted(list(all_days - existing))
        return missing

    def get_coverage(self, exchange: str, trading_pair: str, interval: str) -> List[int]:
        """
        è·å–æ•°æ®çš„è¦†ç›–å›¾è°± (Health Ribbon) - ä¼˜åŒ–ç‰ˆ
        """
        days = self.list_existing_days(exchange, trading_pair, interval)
        if not days:
            return [0] * 100
            
        start, end = days[0], days[-1]
        total_dist = (end - start).days + 1
        
        if total_dist <= 1:
            return [1] * 100
            
        points = [0] * 100
        day_set = set(days)
        
        for i in range(100):
            target_day_count = int(i * (total_dist - 1) / 99)
            target_day = start + timedelta(days=target_day_count)
            if target_day in day_set:
                points[i] = 1
        
        return points

    def get_summary(self, fast: bool = True, audit: bool = False) -> Dict:
        """
        è·å–å­˜å‚¨å±‚ç»Ÿè®¡ä¿¡æ¯ã€‚
        fast=True æ—¶è·³è¿‡è¡Œæ•°ç»Ÿè®¡ï¼Œä»…ç»Ÿè®¡æ–‡ä»¶æ•°å’Œå¤§å°ã€‚
        audit=True æ—¶æ‰§è¡Œæ·±åº¦å®¡è®¡ï¼Œæ£€æŸ¥æ–‡ä»¶çš„ç‰©ç†è¡Œæ•°ã€‚
        """
        stats = {
            "total_files": 0,
            "total_size_mb": 0.0,
            "pairs": {}
        }
        
        if not self.base_path.exists():
            return stats
            
        # âš¡ é‡‡ç”¨å±‚çº§é€’å½’æ›¿ä»£ rglob ä»¥æå‡æµ·é‡å°æ–‡ä»¶éå†é€Ÿåº¦ä¸ç¨³å®šæ€§
        depth_files = []
        try:
            for exch_dir in self.base_path.iterdir():
                if not exch_dir.is_dir(): continue
                for pair_dir in exch_dir.iterdir():
                    if not pair_dir.is_dir(): continue
                    for int_dir in pair_dir.iterdir():
                        if not int_dir.is_dir(): continue
                        # éå†å¹´/æœˆ
                        for year_dir in int_dir.iterdir():
                            if not year_dir.is_dir(): continue
                            for month_dir in year_dir.iterdir():
                                if not month_dir.is_dir(): continue
                                for f in month_dir.iterdir():
                                    if f.suffix == ".csv":
                                        depth_files.append(f)
        except Exception as e:
            logging.error(f"Traversal failed: {e}")

        for file in depth_files:
            stats["total_files"] += 1
            try:
                f_stat = file.stat()
                file_size_mb = f_stat.st_size / (1024 * 1024)
                stats["total_size_mb"] += file_size_mb
                
                parts = file.relative_to(self.base_path).parts
                if len(parts) >= 3:
                    exch, pair, interval = parts[0], parts[1], parts[2]
                    key = f"{exch}:{pair}:{interval}"
                    if key not in stats["pairs"]:
                        stats["pairs"][key] = {
                            "count": 0, 
                            "start": None, "end": None, 
                            "total_rows": 0,
                            "missing_days": 0,
                            "incomplete_days": 0,  # æ–°å¢ï¼šæ£€æµ‹è¡Œæ•°ä¸è¶³çš„å¤©æ•°
                            "gap_segments": 0,
                            "days_list": set(),
                            "incomplete_list": []  # æ–°å¢ï¼šè®°å½•å…·ä½“çš„å¼‚å¸¸æ—¥æœŸ
                        }
                    
                    p_stats = stats["pairs"][key]
                    p_stats["count"] += 1
                    
                    # å®šä¹‰é¢„æœŸè¡Œæ•°
                    expected_rows = 1440 if interval == "1m" else 24 if interval == "1h" else 0
                    
                    actual_rows = 0
                    if not fast or audit:
                        try:
                            # æ·±åº¦å®¡è®¡ï¼šç‰©ç†è¯»å–è¡Œæ•°
                            actual_rows = len(pd.read_csv(file, usecols=[0]))
                            p_stats["total_rows"] += actual_rows
                            
                            # è´¨é‡æ ¡éªŒï¼šå¦‚æœè¡Œæ•°ä¸è¾¾æ ‡ï¼Œæ ‡è®°ä¸ºå¼‚å¸¸
                            if expected_rows > 0 and actual_rows < expected_rows:
                                p_stats["incomplete_days"] += 1
                                day_str = file.stem
                                p_stats["incomplete_list"].append(day_str)
                        except: pass
                    else:
                        # å¿«é€Ÿæ¨¡å¼ä¸‹ä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®— (é’ˆå¯¹ 1m, 1h)
                        # å¦‚æœæ–‡ä»¶å¤ªå° (ä¾‹å¦‚ < 10KB æ¯åˆ†é’Ÿæ•°æ®)ï¼Œå¯èƒ½ä¹Ÿæ˜¯å¼‚å¸¸ï¼Œä½†è¿™é‡Œæš‚ä¸å¼ºåˆ¶
                        if interval == "1m": p_stats["total_rows"] += 1440
                        elif interval == "1h": p_stats["total_rows"] += 24
                        else: p_stats["total_rows"] += 100
                        
                    # è§£ææ—¥æœŸ
                    day_str = file.stem
                    try:
                        day = datetime.strptime(day_str, "%Y-%m-%d").date()
                        p_stats["days_list"].add(day)
                        if p_stats["start"] is None or day < p_stats["start"]: p_stats["start"] = day
                        if p_stats["end"] is None or day > p_stats["end"]: p_stats["end"] = day
                    except: continue
            except: continue
        
        # è®¡ç®—ç¼ºå£ç»Ÿè®¡
        for key, p_stats in stats["pairs"].items():
            if p_stats["start"] and p_stats["end"]:
                total_days = (p_stats["end"] - p_stats["start"]).days + 1
                p_stats["missing_days"] = max(0, total_days - p_stats["count"])
                
                sorted_days = sorted(list(p_stats["days_list"]))
                gap_segments = 0
                if sorted_days:
                    for i in range(len(sorted_days) - 1):
                        if (sorted_days[i+1] - sorted_days[i]).days > 1:
                            gap_segments += 1
                p_stats["gap_segments"] = gap_segments
            
            if "days_list" in p_stats:
                del p_stats["days_list"]
                
        stats["total_size_mb"] = round(stats["total_size_mb"], 2)
        return stats
