import os
import pandas as pd
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import List, Optional, Union, Dict

class LakeStorage:
    """
    åˆ†ç‰‡å­˜å‚¨ç®¡ç†å™¨ (Partitioned Storage Manager)
    è´Ÿè´£å°†è¡Œæƒ…æ•°æ®æŒ‰å¤©å­˜å‚¨åœ¨ç‹¬ç«‹çš„æ–‡ä»¶ä¸­ï¼Œé˜²æ­¢å¹¶å‘å†²çªã€‚
    ç›®å½•ç»“æ„: base_path/{exchange}/{trading_pair}/{interval}/{year}/{month}/{date}.csv
    """
    def __init__(self, base_path: Union[str, Path, None] = None):
        if base_path:
            self.base_path = Path(base_path)
        else:
            # âš¡ è‡ªåŠ¨æ¢æµ‹è·¯å¾„ï¼šä¼˜å…ˆçº§ Env > Rel Path > Package Path
            env_path = os.getenv("DATA_LAKE_PATH")
            if env_path:
                self.base_path = Path(env_path)
            else:
                rel_path = Path("data/lake")
                if rel_path.exists():
                    self.base_path = rel_path
                else:
                    # æ¢æµ‹åŒ…è·¯å¾„ (é’ˆå¯¹ Docker æŒ‚è½½ site-packages æƒ…å†µ)
                    pkg_path = Path(__file__).parent.parent / "data" / "lake"
                    self.base_path = pkg_path
        
        self.base_path.mkdir(parents=True, exist_ok=True)
        # æ‰“å°æ¢æµ‹ç»“æœä»¥ä¾¿è°ƒè¯•
        import logging
        logging.info(f"ğŸ›¡ï¸ LakeStorage initialized at: {self.base_path.absolute()}")

    def get_partition_path(self, exchange: str, trading_pair: str, interval: str, day: Union[date, str]) -> Path:
        """è·å–ç‰¹å®šæ—¥æœŸçš„åˆ†ç‰‡æ–‡ä»¶è·¯å¾„"""
        if isinstance(day, str):
            day = datetime.strptime(day, "%Y-%m-%d").date()
            
        year = str(day.year)
        month = f"{day.month:02d}"
        filename = f"{day.isoformat()}.csv"
        
        path = self.base_path / exchange / trading_pair / interval / year / month / filename
        return path

    def save_day_data(self, df: pd.DataFrame, exchange: str, trading_pair: str, interval: str, day: date):
        """åŸå­æ€§ä¿å­˜ä¸€æ•´å¤©çš„æ•°æ®"""
        path = self.get_partition_path(exchange, trading_pair, interval, day)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å†™å…¥å†é‡å‘½åï¼Œç¡®ä¿åŸå­æ€§
        tmp_path = path.with_suffix(".tmp")
        df.to_csv(tmp_path, index=False)
        tmp_path.replace(path)

    def load_day_data(self, exchange: str, trading_pair: str, interval: str, day: date) -> Optional[pd.DataFrame]:
        """åŠ è½½ç‰¹å®šæ—¥æœŸçš„æ•°æ®"""
        path = self.get_partition_path(exchange, trading_pair, interval, day)
        if not path.exists():
            return None
        return pd.read_csv(path)

    def list_existing_days(self, exchange: str, trading_pair: str, interval: str) -> List[date]:
        """åˆ—å‡ºå·²å­˜åœ¨çš„æ‰€æœ‰å¤© (ä¼˜åŒ–ç‰ˆï¼šé¿å… glob)"""
        dir_path = self.base_path / exchange / trading_pair / interval
        if not dir_path.exists():
            return []
            
        existing_days = []
        # æŒ‰ç…§ YYYY/MM ç»“æ„éå†
        for year_dir in dir_path.iterdir():
            if not year_dir.is_dir(): continue
            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir(): continue
                for file in month_dir.iterdir():
                    if file.suffix == ".csv":
                        try:
                            day_str = file.stem
                            day = datetime.strptime(day_str, "%Y-%m-%d").date()
                            existing_days.append(day)
                        except: continue
        return sorted(existing_days)

    def get_missing_days(self, exchange: str, trading_pair: str, interval: str) -> List[date]:
        """è·å–å·²æœ‰èŒƒå›´å†…çš„æ‰€æœ‰ç¼ºå¤±æ—¥æœŸ"""
        days = self.list_existing_days(exchange, trading_pair, interval)
        if not days:
            return []
        
        start, end = days[0], days[-1]
        all_days = set()
        curr = start
        while curr <= end:
            all_days.add(curr)
            curr += timedelta(days=1)
            
        existing = set(days)
        missing = sorted(list(all_days - existing))
        return missing

    def get_coverage(self, exchange: str, trading_pair: str, interval: str) -> List[int]:
        """
        è·å–æ•°æ®çš„è¦†ç›–å›¾è°± (Health Ribbon) - ä¼˜åŒ–ç‰ˆ
        """
        days = self.list_existing_days(exchange, trading_pair, interval)
        if not days:
            return [0] * 100
            
        start, end = days[0], days[-1]
        total_dist = (end - start).days + 1
        
        if total_dist <= 1:
            return [1] * 100
            
        points = [0] * 100
        day_set = set(days)
        
        for i in range(100):
            target_day_count = int(i * (total_dist - 1) / 99)
            target_day = start + timedelta(days=target_day_count)
            if target_day in day_set:
                points[i] = 1
        
        return points

    def get_summary(self, fast: bool = True, audit: bool = False) -> Dict:
        """
        è·å–å­˜å‚¨å±‚ç»Ÿè®¡ä¿¡æ¯ã€‚
        fast=True æ—¶è·³è¿‡è¡Œæ•°ç»Ÿè®¡ï¼Œä»…ç»Ÿè®¡æ–‡ä»¶æ•°å’Œå¤§å°ã€‚
        audit=True æ—¶æ‰§è¡Œæ·±åº¦å®¡è®¡ï¼Œæ£€æŸ¥æ–‡ä»¶çš„ç‰©ç†è¡Œæ•°ã€‚
        """
        stats = {
            "total_files": 0,
            "total_size_mb": 0.0,
            "pairs": {}
        }
        
        if not self.base_path.exists():
            return stats
            
        # ä¼˜åŒ–éå†é€»è¾‘
        for file in self.base_path.rglob("*.csv"):
            stats["total_files"] += 1
            try:
                f_stat = file.stat()
                file_size_mb = f_stat.st_size / (1024 * 1024)
                stats["total_size_mb"] += file_size_mb
                
                parts = file.relative_to(self.base_path).parts
                if len(parts) >= 3:
                    exch, pair, interval = parts[0], parts[1], parts[2]
                    key = f"{exch}:{pair}:{interval}"
                    if key not in stats["pairs"]:
                        stats["pairs"][key] = {
                            "count": 0, 
                            "start": None, "end": None, 
                            "total_rows": 0,
                            "missing_days": 0,
                            "incomplete_days": 0,  # æ–°å¢ï¼šæ£€æµ‹è¡Œæ•°ä¸è¶³çš„å¤©æ•°
                            "gap_segments": 0,
                            "days_list": set(),
                            "incomplete_list": []  # æ–°å¢ï¼šè®°å½•å…·ä½“çš„å¼‚å¸¸æ—¥æœŸ
                        }
                    
                    p_stats = stats["pairs"][key]
                    p_stats["count"] += 1
                    
                    # å®šä¹‰é¢„æœŸè¡Œæ•°
                    expected_rows = 1440 if interval == "1m" else 24 if interval == "1h" else 0
                    
                    actual_rows = 0
                    if not fast or audit:
                        try:
                            # æ·±åº¦å®¡è®¡ï¼šç‰©ç†è¯»å–è¡Œæ•°
                            actual_rows = len(pd.read_csv(file, usecols=[0]))
                            p_stats["total_rows"] += actual_rows
                            
                            # è´¨é‡æ ¡éªŒï¼šå¦‚æœè¡Œæ•°ä¸è¾¾æ ‡ï¼Œæ ‡è®°ä¸ºå¼‚å¸¸
                            if expected_rows > 0 and actual_rows < expected_rows:
                                p_stats["incomplete_days"] += 1
                                day_str = file.stem
                                p_stats["incomplete_list"].append(day_str)
                        except: pass
                    else:
                        # å¿«é€Ÿæ¨¡å¼ä¸‹ä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®— (é’ˆå¯¹ 1m, 1h)
                        # å¦‚æœæ–‡ä»¶å¤ªå° (ä¾‹å¦‚ < 10KB æ¯åˆ†é’Ÿæ•°æ®)ï¼Œå¯èƒ½ä¹Ÿæ˜¯å¼‚å¸¸ï¼Œä½†è¿™é‡Œæš‚ä¸å¼ºåˆ¶
                        if interval == "1m": p_stats["total_rows"] += 1440
                        elif interval == "1h": p_stats["total_rows"] += 24
                        else: p_stats["total_rows"] += 100
                        
                    # è§£ææ—¥æœŸ
                    day_str = file.stem
                    try:
                        day = datetime.strptime(day_str, "%Y-%m-%d").date()
                        p_stats["days_list"].add(day)
                        if p_stats["start"] is None or day < p_stats["start"]: p_stats["start"] = day
                        if p_stats["end"] is None or day > p_stats["end"]: p_stats["end"] = day
                    except: continue
            except: continue
        
        # è®¡ç®—ç¼ºå£ç»Ÿè®¡
        for key, p_stats in stats["pairs"].items():
            if p_stats["start"] and p_stats["end"]:
                total_days = (p_stats["end"] - p_stats["start"]).days + 1
                p_stats["missing_days"] = max(0, total_days - p_stats["count"])
                
                sorted_days = sorted(list(p_stats["days_list"]))
                gap_segments = 0
                if sorted_days:
                    for i in range(len(sorted_days) - 1):
                        if (sorted_days[i+1] - sorted_days[i]).days > 1:
                            gap_segments += 1
                p_stats["gap_segments"] = gap_segments
            
            if "days_list" in p_stats:
                del p_stats["days_list"]
                
        stats["total_size_mb"] = round(stats["total_size_mb"], 2)
        return stats
